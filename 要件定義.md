# LLMマルチ会話システム 要件定義書（改訂版）

## 1. プロジェクト概要

### 1.1 目的
**AI同士の自動会話を観察するためのツール開発**
- ユーザーは会話の観察者として、AI同士の議論・やりとりを楽しむ
- 従量課金API（ChatGPT, Claude）の費用暴走を防ぐため、トークン数で制限
- 3つのAI（ChatGPT, Claude, Gemini）が平等にランダムな順序で会話

### 1.2 想定利用者
- AI同士の会話を観察して楽しみたい個人ユーザー
- コストを抑えながらAI会話実験をしたい人
- 各LLMの個性や反応の違いを観察したい人

## 2. 機能要件

### 2.1 コア機能（必須）

#### 2.1.1 AI同士の自動会話
- **機能**: 3つのAIが自動で会話を続ける（ユーザーは観察のみ）
- **仕様**: 
  - **会話順序: ランダム選択**（よりリアルな会話を再現）
  - 直前に発言したAIは次の発言者から除外（連続発言防止）
  - 初期トピック設定後は完全自動進行
  - ユーザーは途中で介入せず、観察に専念
  - 各AIの応答待機時間設定（APIレート制限対応）

#### 2.1.2 リアルタイムトークン・コスト表示
- **機能**: トークン使用量と従量課金APIの費用をリアルタイム表示
- **仕様**:
  ```
  費用監視対象:
  - ChatGPT-4o: Input $2.50/1M, Output $10.00/1M tokens
  - Claude 3.5 Sonnet: Input $3.00/1M, Output $15.00/1M tokens
  - Gemini 2.0 Flash: 無料枠内は監視対象外
  ```
  - 累計トークン数をリアルタイム表示
  - 累計費用をリアルタイム表示
  - 各発言ごとのトークン数・費用を表示
  - 残りトークン数の表示

#### 2.1.3 トークン数制限・自動停止
- **機能**: 設定トークン数上限で自動停止（費用の暴走を防ぐ）
- **仕様**:
  - **トークン数上限**: 50,000 または 100,000 tokens（選択可能）
  - 累計トークン数をリアルタイム表示
  - 90%到達時に警告表示
  - 100%到達時に即座に停止
  - 緊急停止ボタン（Ctrl+C）

#### 2.1.4 観察用ログ記録
- **機能**: AI同士の会話を観察・記録（後から読み返し可能）
- **仕様**:
  - リアルタイム会話表示（コンソール）
  - 会話ログのファイル保存（テキスト形式）
  - 発言者の色分け表示
  - タイムスタンプ付き記録

### 2.2 拡張機能（オプション）

#### 2.2.1 会話テーマ設定
- 「哲学について議論」「SFについて語り合う」「料理のレシピ開発」など
- 初期プロンプトのみ設定、後は完全にAI任せ

#### 2.2.2 観察UI改善
- AI発言の色分け表示（ChatGPT=青、Claude=緑、Gemini=赤）
- リアルタイム費用メーター表示
- 会話の進行速度調整（早送り/一時停止）

#### 2.2.3 実験設定機能
- **トークン上限選択**: 50,000 または 100,000 tokens
- 発言文字数制限（長すぎる応答を防ぐ）
- 休息時間設定（API使用量を抑制）
- 会話終了条件の設定

## 3. 技術要件

### 3.1 実行環境
- **対象OS**: Windows 10+, macOS 11+, Linux Ubuntu 20.04+
- **Python**: 3.10以上
- **実行場所**: ローカル環境（Google Colab対応も考慮）

### 3.2 使用ライブラリ
```python
# 必須ライブラリ
openai>=1.0.0          # ChatGPT API
anthropic>=0.8.0       # Claude API  
google-generativeai    # Gemini API
tiktoken              # トークン計算
pandas                # データ処理
python-dotenv         # 環境変数管理

# オプションライブラリ
matplotlib            # グラフ表示
rich                  # コンソール表示
pydantic             # 設定管理
```

### 3.3 APIキー管理
- `.env`ファイル使用
- 環境変数からの読み込み
- エラーハンドリング（キー未設定時の適切な通知）

## 4. 非機能要件

### 4.1 パフォーマンス
- API応答時間: 各リクエスト30秒以内
- メモリ使用量: 500MB以下
- ログファイルサイズ: セッション当たり100MB以下

### 4.2 信頼性
- APIエラー時の適切なリトライ機能
- ネットワーク切断時の状態保存
- 異常終了時の部分ログ保護

### 4.3 セキュリティ
- APIキーの平文保存禁止
- ログファイルの適切な権限設定
- 個人情報が含まれる場合の匿名化

## 5. 制約事項

### 5.1 技術制約
- API利用規約の遵守
- レート制限の考慮（各社API制限内での実行）
- 無限ループ防止機構の実装

### 5.2 コスト制約
- **最重要**: トークン数制限で費用の暴走を絶対に防ぐ
- トークン上限: 50,000 または 100,000 tokens
- 「観察して楽しむ」程度の利用に限定
- 長時間放置での無制限実行は禁止

### 5.3 運用制約
- ユーザーは基本的に観察のみ（途中介入なし）
- **AI間の発言は平等**（特定のAIへの偏りなし）
- 手動でのAPIキー設定が必要
- 初期トピック設定後は完全自動進行
- 緊急時の手動停止機能は必須

## 6. 成果物

### 6.1 プログラム
- `main.py`: メイン実行ファイル
- `config.py`: 設定管理
- `llm_manager.py`: LLM API管理
- `cost_monitor.py`: コスト監視
- `logger.py`: ログ管理

### 6.2 設定ファイル
- `.env.example`: 環境変数テンプレート
- `config.json`: デフォルト設定
- `requirements.txt`: 依存関係

### 6.3 ドキュメント
- `README.md`: 使用方法
- `SETUP.md`: セットアップガイド
- `API_KEYS.md`: APIキー取得方法

## 7. 開発フェーズ

### フェーズ1: 基本機能実装
- [ ] API接続確認
- [ ] 基本会話ループ
- [ ] トークン計測

### フェーズ2: 監視機能実装  
- [ ] コスト計算
- [ ] 自動停止機能
- [ ] ログ保存

### フェーズ3: 拡張機能実装
- [ ] UI改善
- [ ] テーマ設定
- [ ] グラフ表示

## 8. テスト計画

### 8.1 単体テスト
- 各LLM API接続テスト
- トークン計算精度テスト
- コスト計算精度テスト

### 8.2 統合テスト
- エンドツーエンド会話テスト
- 自動停止機能テスト
- ログ保存完全性テスト

### 8.3 負荷テスト
- 長時間実行テスト
- メモリリークテスト
- API制限エラーハンドリングテスト