import time
import random
from typing import Optional, List, Dict, Any
from abc import ABC, abstractmethod

import openai
import anthropic
import google.generativeai as genai

from config import config

class BaseLLM(ABC):
    """LLMåŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, name: str):
        self.name = name
        self.is_available = False
    
    @abstractmethod
    def initialize(self) -> bool:
        """åˆæœŸåŒ–"""
        pass
    
    @abstractmethod
    def generate_response(self, messages: List[Dict], max_tokens: int = 500) -> str:
        """å¿œç­”ç”Ÿæˆ"""
        pass
    
    def create_conversation_context(self, previous_messages: List[str], current_topic: str) -> List[Dict]:
        """ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ"""
        context = []
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        system_prompt = f"""ã‚ãªãŸã¯ä»–ã®AIã¨ä¼šè©±ã‚’ã—ã¦ã„ã¾ã™ã€‚
ç¾åœ¨ã®ãƒˆãƒ”ãƒƒã‚¯: {current_topic}

ä¼šè©±ã®ãƒ«ãƒ¼ãƒ«:
1. è‡ªç„¶ã§èˆˆå‘³æ·±ã„ä¼šè©±ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„
2. ä»–ã®AIã®ç™ºè¨€ã«å¯¾ã—ã¦é©åˆ‡ã«åå¿œã—ã¦ãã ã•ã„  
3. æ–°ã—ã„è¦³ç‚¹ã‚„è³ªå•ã‚’æä¾›ã—ã¦ãã ã•ã„
4. ç°¡æ½”ã«ï¼ˆ500æ–‡å­—ä»¥å†…ã§ï¼‰å›ç­”ã—ã¦ãã ã•ã„
5. ã‚ãªãŸã®å€‹æ€§ã‚’æ´»ã‹ã—ãŸç™ºè¨€ã‚’ã—ã¦ãã ã•ã„
6. ç™ºè¨€ã«ä»–ã®AIã®åå‰ã¯å«ã‚ãšã€ç›´æ¥å¿œç­”ã—ã¦ãã ã•ã„"""

        context.append({"role": "system", "content": system_prompt})
        
        # éå»ã®ä¼šè©±å±¥æ­´ã‚’è¿½åŠ ï¼ˆæœ€æ–°10ä»¶ã¾ã§ï¼‰
        recent_messages = previous_messages[-10:] if len(previous_messages) > 10 else previous_messages
        
        for i, msg in enumerate(recent_messages):
            # ç™ºè¨€è€…åã‚’é™¤å»ï¼ˆã€ŒChatGPT:ã€ã€ŒClaude:ã€ã€ŒGemini:ã€ã‚’å‰Šé™¤ï¼‰
            clean_msg = msg
            if ": " in msg:
                parts = msg.split(": ", 1)
                if parts[0] in ["ChatGPT", "Claude", "Gemini", "ä¼šè©±ãƒˆãƒ”ãƒƒã‚¯"]:
                    clean_msg = parts[1] if len(parts) > 1 else msg
            
            role = "assistant" if i % 2 == 0 else "user"
            context.append({"role": role, "content": clean_msg})
        
        return context

class ChatGPTLLM(BaseLLM):
    """ChatGPT APIç®¡ç†"""
    
    def __init__(self):
        super().__init__("ChatGPT")
        self.client = None
        self.model = "gpt-4o"
    
    def initialize(self) -> bool:
        """åˆæœŸåŒ–"""
        try:
            if not config.openai_api_key:
                print("âš ï¸ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
            
            self.client = openai.OpenAI(api_key=config.openai_api_key)
            
            # æ¥ç¶šãƒ†ã‚¹ãƒˆ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=10
            )
            
            self.is_available = True
            print(f"âœ… {self.name} åˆæœŸåŒ–å®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ {self.name} åˆæœŸåŒ–å¤±æ•—: {e}")
            return False
    
    def generate_response(self, messages: List[Dict], max_tokens: int = 500) -> str:
        """å¿œç­”ç”Ÿæˆ"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            raise Exception(f"{self.name} APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")

class ClaudeLLM(BaseLLM):
    """Claude APIç®¡ç†"""
    
    def __init__(self):
        super().__init__("Claude")
        self.client = None
        self.model = "claude-3-5-sonnet-20241022"
    
    def initialize(self) -> bool:
        """åˆæœŸåŒ–"""
        try:
            if not config.anthropic_api_key:
                print("âš ï¸ Anthropic APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
            
            self.client = anthropic.Anthropic(api_key=config.anthropic_api_key)
            
            # æ¥ç¶šãƒ†ã‚¹ãƒˆ
            response = self.client.messages.create(
                model=self.model,
                max_tokens=10,
                messages=[{"role": "user", "content": "Hello"}]
            )
            
            self.is_available = True
            print(f"âœ… {self.name} åˆæœŸåŒ–å®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ {self.name} åˆæœŸåŒ–å¤±æ•—: {e}")
            return False
    
    def generate_response(self, messages: List[Dict], max_tokens: int = 500) -> str:
        """å¿œç­”ç”Ÿæˆ"""
        try:
            # Claudeã®å ´åˆã€system messageã‚’åˆ†é›¢
            system_message = ""
            user_messages = []
            
            for msg in messages:
                if msg["role"] == "system":
                    system_message = msg["content"]
                else:
                    user_messages.append(msg)
            
            response = self.client.messages.create(
                model=self.model,
                max_tokens=max_tokens,
                system=system_message,
                messages=user_messages,
                temperature=0.7
            )
            
            return response.content[0].text.strip()
            
        except Exception as e:
            raise Exception(f"{self.name} APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")

class GeminiLLM(BaseLLM):
    """Gemini APIç®¡ç†"""
    
    def __init__(self):
        super().__init__("Gemini")
        self.model = None
        self.model_name = "gemini-2.0-flash-exp"
    
    def initialize(self) -> bool:
        """åˆæœŸåŒ–"""
        try:
            if not config.google_api_key:
                print("âš ï¸ Google APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
            
            genai.configure(api_key=config.google_api_key)
            self.model = genai.GenerativeModel(self.model_name)
            
            # æ¥ç¶šãƒ†ã‚¹ãƒˆ
            response = self.model.generate_content("Hello")
            
            self.is_available = True
            print(f"âœ… {self.name} åˆæœŸåŒ–å®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ {self.name} åˆæœŸåŒ–å¤±æ•—: {e}")
            return False
    
    def generate_response(self, messages: List[Dict], max_tokens: int = 500) -> str:
        """å¿œç­”ç”Ÿæˆ"""
        try:
            # Geminiã®å ´åˆã€ä¼šè©±å±¥æ­´ã‚’å˜ä¸€ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«çµåˆ
            prompt = ""
            
            for msg in messages:
                if msg["role"] == "system":
                    prompt += f"System: {msg['content']}\n\n"
                elif msg["role"] == "user":
                    prompt += f"User: {msg['content']}\n\n"
                elif msg["role"] == "assistant":
                    prompt += f"Assistant: {msg['content']}\n\n"
            
            prompt += "ã‚ãªãŸã®å¿œç­”:"
            
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=max_tokens,
                    temperature=0.7
                )
            )
            
            return response.text.strip()
            
        except Exception as e:
            raise Exception(f"{self.name} APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")

class LLMManager:
    """LLMç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.llms = {
            "ChatGPT": ChatGPTLLM(),
            "Claude": ClaudeLLM(),
            "Gemini": GeminiLLM()
        }
        self.available_llms = []
        self.conversation_history = []
        self.previous_speaker = None
    
    def initialize_all(self) -> List[str]:
        """å…¨LLMã‚’åˆæœŸåŒ–"""
        print("ğŸ”§ LLMåˆæœŸåŒ–ä¸­...")
        
        for name, llm in self.llms.items():
            if llm.initialize():
                self.available_llms.append(name)
        
        if not self.available_llms:
            raise Exception("åˆ©ç”¨å¯èƒ½ãªLLMãŒã‚ã‚Šã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        print(f"âœ… åˆ©ç”¨å¯èƒ½ãªLLM: {', '.join(self.available_llms)}")
        return self.available_llms
    
    def select_next_speaker(self) -> str:
        """æ¬¡ã®ç™ºè¨€è€…ã‚’ãƒ©ãƒ³ãƒ€ãƒ é¸æŠï¼ˆç›´å‰ã®ç™ºè¨€è€…ã¯é™¤å¤–ï¼‰"""
        candidates = [name for name in self.available_llms if name != self.previous_speaker]
        
        if not candidates:
            candidates = self.available_llms
        
        next_speaker = random.choice(candidates)
        self.previous_speaker = next_speaker
        return next_speaker
    
    def generate_response(self, speaker: str, topic: str, max_tokens: int = 500) -> str:
        """æŒ‡å®šã•ã‚ŒãŸLLMã§å¿œç­”ã‚’ç”Ÿæˆ"""
        if speaker not in self.available_llms:
            raise Exception(f"{speaker} ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        llm = self.llms[speaker]
        context = llm.create_conversation_context(self.conversation_history, topic)
        
        try:
            response = llm.generate_response(context, max_tokens)
            
            # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
            self.conversation_history.append(f"{speaker}: {response}")
            
            return response
            
        except Exception as e:
            print(f"âŒ {speaker} ã®å¿œç­”ç”Ÿæˆã«å¤±æ•—: {e}")
            raise
    
    def add_initial_message(self, topic: str):
        """åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¼šè©±å±¥æ­´ã«è¿½åŠ """
        self.conversation_history.append(f"ä¼šè©±ãƒˆãƒ”ãƒƒã‚¯: {topic}")
    
    def get_conversation_length(self) -> int:
        """ä¼šè©±ã®é•·ã•ã‚’å–å¾—"""
        return len(self.conversation_history)
    
    def wait_for_rate_limit(self, wait_time: int = 2):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œã®å¾…æ©Ÿ"""
        if wait_time > 0:
            print(f"â³ {wait_time}ç§’å¾…æ©Ÿä¸­...")
            time.sleep(wait_time)

def create_llm_manager() -> LLMManager:
    """LLMãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ"""
    return LLMManager() 