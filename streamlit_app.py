#!/usr/bin/env python3
"""
LLMãƒãƒ«ãƒä¼šè©±ã‚·ã‚¹ãƒ†ãƒ  - Streamlit Web UI
AIåŒå£«ã®è‡ªå‹•ä¼šè©±ã‚’è¦³å¯Ÿã™ã‚‹ãŸã‚ã®Webã‚¢ãƒ—ãƒª
"""

import streamlit as st
import time
import threading
from datetime import datetime
from typing import Optional

from config import setup_config, config
from cost_monitor import create_cost_monitor
from logger import create_logger
from llm_manager import create_llm_manager

# ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆèƒŒæ™¯ã‚’ç™½ã«ï¼‰
st.set_page_config(
    page_title="AIåŒå£«ã®ä¼šè©±ã‚’è¦³å¯Ÿ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSSï¼ˆChatGPTãƒ©ã‚¤ã‚¯ãªã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
st.markdown("""
<style>
/* èƒŒæ™¯è‰²ã‚’ç™½ã« */
.main {
    background-color: white;
}

/* ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚¹ã‚¿ã‚¤ãƒ« */
.chat-message {
    padding: 1rem;
    border-radius: 10px;
    margin: 0.5rem 0;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    color: #000000 !important;  /* é»’æ–‡å­—ã‚’å¼·åˆ¶ */
}

/* ChatGPTã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆé’ç³»ï¼‰ */
.chatgpt-message {
    background-color: #f7f9fc;
    border-left: 4px solid #4285f4;
    color: #1a1a1a !important;  /* æ¿ƒã„é»’æ–‡å­— */
}

/* Claudeã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆã‚ªãƒ¬ãƒ³ã‚¸ç³»ï¼‰ */
.claude-message {
    background-color: #fff8f0;
    border-left: 4px solid #ff8c00;
    color: #1a1a1a !important;  /* æ¿ƒã„é»’æ–‡å­— */
}

/* Geminiã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆç·‘ç³»ï¼‰ */
.gemini-message {
    background-color: #f0fff4;
    border-left: 4px solid #00c851;
    color: #1a1a1a !important;  /* æ¿ƒã„é»’æ–‡å­— */
}

/* ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */
.system-message {
    background-color: #f8f9fa;
    border-left: 4px solid #6c757d;
    color: #1a1a1a !important;  /* æ¿ƒã„é»’æ–‡å­— */
    font-style: italic;
}

/* ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…ã®ãƒ†ã‚­ã‚¹ãƒˆ */
.chat-message div {
    color: #1a1a1a !important;  /* æ¿ƒã„é»’æ–‡å­— */
}

/* ã‚¢ã‚¤ã‚³ãƒ³ */
.speaker-icon {
    font-size: 1.2em;
    margin-right: 0.5rem;
}

/* ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼ */
.status-bar {
    background-color: #f8f9fa;
    padding: 1rem;
    border-radius: 5px;
    border: 1px solid #dee2e6;
}

/* ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ */
.progress-bar {
    margin: 1rem 0;
}

/* Streamlitè¦ç´ ã®æ–‡å­—è‰²ã‚’ç¢ºå®Ÿã«é»’ã«ã™ã‚‹ */
.stMarkdown, .stText {
    color: #1a1a1a !important;
}
</style>
""", unsafe_allow_html=True)

def get_speaker_style(speaker: str) -> tuple[str, str]:
    """è©±è€…ã«å¿œã˜ãŸã‚¹ã‚¿ã‚¤ãƒ«ã¨ã‚¢ã‚¤ã‚³ãƒ³ã‚’å–å¾—"""
    styles = {
        "ChatGPT": ("chatgpt-message", "ğŸ¤–"),
        "Claude": ("claude-message", "ğŸ§ "),
        "Gemini": ("gemini-message", "â­"),
    }
    return styles.get(speaker, ("system-message", "â“"))

def display_message(speaker: str, content: str, tokens: int, cost: float):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    style_class, icon = get_speaker_style(speaker)
    
    # Streamlitã®æ¨™æº–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ç¢ºå®Ÿã«è¡¨ç¤º
    with st.container():
        # ãƒ˜ãƒƒãƒ€ãƒ¼éƒ¨åˆ†
        col1, col2 = st.columns([3, 1])
        with col1:
            st.markdown(f"### {icon} **{speaker}**")
        with col2:
            st.caption(f"{tokens} tokens | ${cost:.4f}")
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ï¼ˆèƒŒæ™¯è‰²ä»˜ãï¼‰
        if speaker == "ChatGPT":
            st.info(content)
        elif speaker == "Claude":
            st.warning(content)
        elif speaker == "Gemini":
            st.success(content)
        else:
            st.write(content)
        
        st.divider()

def display_status(cost_monitor):
    """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º"""
    status = cost_monitor.get_status_summary()
    percentage = status['usage_percentage']
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
    progress_color = "red" if percentage >= 100 else "orange" if percentage >= 90 else "green"
    st.progress(min(percentage / 100, 1.0))
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡", f"{status['total_tokens']:,}", 
                 f"/ {cost_monitor.token_limit:,}")
    
    with col2:
        st.metric("ä½¿ç”¨ç‡", f"{percentage:.1f}%")
    
    with col3:
        st.metric("ç·ã‚³ã‚¹ãƒˆ", f"${status['total_cost_usd']:.4f}")
    
    with col4:
        st.metric("æ®‹ã‚Šãƒˆãƒ¼ã‚¯ãƒ³", f"{status['remaining_tokens']:,}")

def initialize_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
    if 'conversation_active' not in st.session_state:
        st.session_state.conversation_active = False
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'total_messages' not in st.session_state:
        st.session_state.total_messages = 0
    if 'session_config' not in st.session_state:
        st.session_state.session_config = None
    if 'cost_monitor' not in st.session_state:
        st.session_state.cost_monitor = None
    if 'llm_manager' not in st.session_state:
        st.session_state.llm_manager = None
    if 'auto_step' not in st.session_state:
        st.session_state.auto_step = False
    if 'last_message_time' not in st.session_state:
        st.session_state.last_message_time = None

def setup_sidebar():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    with st.sidebar:
        st.title("ğŸ¤– AIä¼šè©±è¨­å®š")
        
        # APIã‚­ãƒ¼è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.subheader("ğŸ”‘ APIã‚­ãƒ¼è¨­å®š")
        st.info("âš ï¸ å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè‡ªåˆ†ã®APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        
        # OpenAI API Key
        openai_key = st.text_input(
            "OpenAI API Key (ChatGPTç”¨)",
            type="password",
            help="https://platform.openai.com/api-keys ã‹ã‚‰å–å¾—"
        )
        
        # Anthropic API Key
        anthropic_key = st.text_input(
            "Anthropic API Key (Claudeç”¨)",
            type="password", 
            help="https://console.anthropic.com/ ã‹ã‚‰å–å¾—ï¼ˆè¦ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆè³¼å…¥ï¼‰"
        )
        
        # Google API Key
        google_key = st.text_input(
            "Google API Key (Geminiç”¨)",
            type="password",
            help="https://makersuite.google.com/app/apikey ã‹ã‚‰å–å¾—"
        )
        
        # APIã‚­ãƒ¼ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        if openai_key:
            st.session_state.openai_api_key = openai_key
        if anthropic_key:
            st.session_state.anthropic_api_key = anthropic_key
        if google_key:
            st.session_state.google_api_key = google_key
        
        # APIã‚­ãƒ¼è¨­å®šçŠ¶æ³ã®è¡¨ç¤º
        api_keys_set = []
        if openai_key:
            api_keys_set.append("âœ… OpenAI (ChatGPT)")
        if anthropic_key:
            api_keys_set.append("âœ… Anthropic (Claude)")
        if google_key:
            api_keys_set.append("âœ… Google (Gemini)")
        
        if api_keys_set:
            st.success(f"è¨­å®šæ¸ˆã¿: {', '.join(api_keys_set)}")
        else:
            st.warning("æœ€ä½2ã¤ã®APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™")
        
        st.divider()
        
        # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™è¨­å®š
        st.subheader("ğŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™")
        token_options = {"20,000 tokens (æ¨å¥¨)": 20000, "50,000 tokens": 50000}
        selected_option = st.selectbox("åˆ¶é™ã‚’é¸æŠ", list(token_options.keys()))
        token_limit = token_options[selected_option]
        
        # ã‚«ã‚¹ã‚¿ãƒ è¨­å®š
        if st.checkbox("ã‚«ã‚¹ã‚¿ãƒ è¨­å®š"):
            token_limit = st.number_input("ã‚«ã‚¹ã‚¿ãƒ ãƒˆãƒ¼ã‚¯ãƒ³æ•°", min_value=1000, max_value=200000, value=20000)
        
        # ãƒ†ãƒ¼ãƒè¨­å®š
        st.subheader("ğŸ¯ ä¼šè©±ãƒ†ãƒ¼ãƒ")
        theme_presets = [
            "ä¸€èˆ¬çš„ãªè©±é¡Œã«ã¤ã„ã¦è‡ªç”±ã«è­°è«–",
            "å“²å­¦ã«ã¤ã„ã¦è­°è«–",
            "SFã«ã¤ã„ã¦èªã‚Šåˆã†",
            "æ–™ç†ã®ãƒ¬ã‚·ãƒ”é–‹ç™º",
            "æŠ€è¡“ã®æœªæ¥ã«ã¤ã„ã¦",
            "å‰µä½œã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è€ƒãˆã‚‹"
        ]
        selected_theme = st.selectbox("ãƒ†ãƒ¼ãƒã‚’é¸æŠ", theme_presets)
        
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ¼ãƒ
        if st.checkbox("ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ¼ãƒ"):
            selected_theme = st.text_input("ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›", value=selected_theme)
        
        st.divider()
        
        # é–‹å§‹/åœæ­¢ãƒœã‚¿ãƒ³
        api_count = len(api_keys_set)
        if not st.session_state.conversation_active:
            if api_count >= 2:
                if st.button("ğŸš€ ä¼šè©±é–‹å§‹", type="primary", use_container_width=True):
                    start_conversation(token_limit, selected_theme)
            else:
                st.button("ğŸš€ ä¼šè©±é–‹å§‹", type="primary", use_container_width=True, disabled=True)
                st.error("æœ€ä½2ã¤ã®APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        else:
            if st.button("ğŸ›‘ ä¼šè©±åœæ­¢", type="secondary", use_container_width=True):
                stop_conversation()
        
        st.divider()
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        st.subheader("â„¹ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        if st.session_state.llm_manager:
            available_llms = st.session_state.llm_manager.available_llms
            for llm in available_llms:
                st.success(f"âœ… {llm}")
        
        # æ–™é‡‘æƒ…å ±
        st.subheader("ğŸ’° æ–™é‡‘ç›®å®‰")
        st.markdown("""
        **20,000ãƒˆãƒ¼ã‚¯ãƒ³ã§ã®æ¦‚ç®—:**
        - ChatGPT: $0.1-0.3
        - Claude: $0.15-0.75
        - Gemini: ç„¡æ–™æ å†…
        """)
        
        # ãƒ˜ãƒ«ãƒ—ãƒªãƒ³ã‚¯
        st.subheader("ğŸ“š ãƒ˜ãƒ«ãƒ—")
        st.markdown("""
        - [OpenAI API](https://platform.openai.com/api-keys)
        - [Anthropic API](https://console.anthropic.com/)
        - [Google AI Studio](https://makersuite.google.com/app/apikey)
        """)

def start_conversation(token_limit: int, theme: str):
    """ä¼šè©±ã‚’é–‹å§‹"""
    # å¤‰æ•°ã‚’äº‹å‰ã«åˆæœŸåŒ–ï¼ˆã‚¹ã‚³ãƒ¼ãƒ—å¯¾ç­–ï¼‰
    openai_key = None
    anthropic_key = None
    google_key = None
    
    try:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰APIã‚­ãƒ¼ã‚’æ˜ç¤ºçš„ã«å–å¾—
        openai_key = getattr(st.session_state, 'openai_api_key', None)
        anthropic_key = getattr(st.session_state, 'anthropic_api_key', None)
        google_key = getattr(st.session_state, 'google_api_key', None)
        
        # APIã‚­ãƒ¼ãŒãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
        api_keys_available = 0
        if openai_key:
            api_keys_available += 1
        if anthropic_key:
            api_keys_available += 1
        if google_key:
            api_keys_available += 1
        
        if api_keys_available < 2:
            st.error("âš ï¸ æœ€ä½2ã¤ã®APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
            return
        
        # configã«APIã‚­ãƒ¼ã‚’æ˜ç¤ºçš„ã«è¨­å®š
        if openai_key:
            config.openai_api_key = openai_key
        if anthropic_key:
            config.anthropic_api_key = anthropic_key
        if google_key:
            config.google_api_key = google_key
        
        # è¨­å®šã‚’ç¢ºå®Ÿã«åæ˜ 
        config.load_api_keys()
        
        # è¨­å®šåˆæœŸåŒ–
        st.session_state.session_config = setup_config(token_limit, theme)
        st.session_state.cost_monitor = create_cost_monitor(token_limit)
        st.session_state.llm_manager = create_llm_manager()
        
        # LLMåˆæœŸåŒ–
        available_models = st.session_state.llm_manager.initialize_all()
        if len(available_models) < 2:
            st.error("âš ï¸ ä¼šè©±ã«ã¯æœ€ä½2ã¤ã®LLMãŒå¿…è¦ã§ã™")
            st.error("ã‚¨ãƒ©ãƒ¼è©³ç´°: APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            return
        
        # åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        st.session_state.llm_manager.add_initial_message(theme)
        st.session_state.messages = []
        st.session_state.total_messages = 0
        st.session_state.conversation_active = True
        st.session_state.last_message_time = None  # åˆæœŸåŒ–
        
        st.success(f"ğŸš€ ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼ãƒ†ãƒ¼ãƒ: {theme}")
        st.success(f"åˆ©ç”¨å¯èƒ½ãªAI: {', '.join(available_models)}")

    except Exception as e:
        st.error(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        st.error(f"è©³ç´°: {traceback.format_exc()}")
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º
        st.error("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
        st.error(f"OpenAI ã‚­ãƒ¼è¨­å®š: {'âœ…' if openai_key else 'âŒ'}")
        st.error(f"Anthropic ã‚­ãƒ¼è¨­å®š: {'âœ…' if anthropic_key else 'âŒ'}")
        st.error(f"Google ã‚­ãƒ¼è¨­å®š: {'âœ…' if google_key else 'âŒ'}")
        st.error(f"Config OpenAI: {'âœ…' if config.openai_api_key else 'âŒ'}")
        st.error(f"Config Anthropic: {'âœ…' if config.anthropic_api_key else 'âŒ'}")
        st.error(f"Config Google: {'âœ…' if config.google_api_key else 'âŒ'}")

def stop_conversation():
    """ä¼šè©±ã‚’åœæ­¢"""
    st.session_state.conversation_active = False
    st.session_state.last_message_time = None
    st.success("ğŸ›‘ ä¼šè©±ã‚’åœæ­¢ã—ã¾ã—ãŸ")

def conversation_step(chat_placeholder):
    """ä¼šè©±ã®1ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œ"""
    if not st.session_state.conversation_active:
        return
    
    try:
        # æ¬¡ã®ç™ºè¨€è€…ã‚’é¸æŠ
        current_speaker = st.session_state.llm_manager.select_next_speaker()
        
        # ã‚¹ãƒ”ãƒŠãƒ¼ã§æ€è€ƒä¸­ã‚’è¡¨ç¤º
        with st.spinner(f"ğŸ¤ {current_speaker} ãŒè€ƒãˆä¸­..."):
            # å¿œç­”ç”Ÿæˆ
            response = st.session_state.llm_manager.generate_response(
                current_speaker,
                st.session_state.session_config.initial_theme,
                st.session_state.session_config.max_response_length
            )
        
        # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¨ã‚³ã‚¹ãƒˆã‚’è¨ˆç®—
        session_tokens, session_cost = st.session_state.cost_monitor.add_usage(
            current_speaker,
            st.session_state.session_config.initial_theme,
            response
        )
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        st.session_state.messages.append({
            'speaker': current_speaker,
            'content': response,
            'tokens': session_tokens,
            'cost': session_cost,
            'timestamp': datetime.now()
        })
        st.session_state.total_messages += 1
        st.session_state.last_message_time = time.time()  # æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ™‚åˆ»ã‚’è¨˜éŒ²
        
        # ãƒãƒ£ãƒƒãƒˆã‚¨ãƒªã‚¢å…¨ä½“ã‚’æ›´æ–°ï¼ˆå…¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å†è¡¨ç¤ºï¼‰
        with chat_placeholder.container():
            for message in st.session_state.messages:
                display_message(
                    message['speaker'],
                    message['content'],
                    message['tokens'],
                    message['cost']
                )
        
        # åˆ¶é™ãƒã‚§ãƒƒã‚¯
        if st.session_state.cost_monitor.is_limit_exceeded():
            st.session_state.conversation_active = False
            return
        
    except Exception as e:
        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    st.title("ğŸ¤– AIåŒå£«ã®ä¼šè©±ã‚’è¦³å¯Ÿ")
    st.markdown("**ChatGPT**ã€**Claude**ã€**Gemini**ãŒè‡ªå‹•ã§ä¼šè©±ã™ã‚‹æ§˜å­ã‚’è¦³å¯Ÿã§ãã¾ã™")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
    initialize_session_state()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
    setup_sidebar()
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    if st.session_state.conversation_active:
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
        if st.session_state.cost_monitor:
            st.subheader("ğŸ“Š ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹")
            display_status(st.session_state.cost_monitor)
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒƒãƒˆè¡¨ç¤ºã‚¨ãƒªã‚¢
        st.subheader("ğŸ’¬ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¼šè©±")
        st.info("ğŸ’¡ AIåŒå£«ãŒè‡ªå‹•ã§ä¼šè©±ã—ã¦ã„ã¾ã™ã€‚å‚è¦³ã—ã¦ãŠæ¥½ã—ã¿ãã ã•ã„ã€‚")
        
        # ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¨ãƒªã‚¢
        chat_placeholder = st.empty()
        
        # æ—¢å­˜ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        if st.session_state.messages:
            with chat_placeholder.container():
                for message in st.session_state.messages:
                    display_message(
                        message['speaker'],
                        message['content'],
                        message['tokens'],
                        message['cost']
                    )
        else:
            with chat_placeholder.container():
                st.write("AIåŒå£«ã®ä¼šè©±ãŒå§‹ã¾ã‚Šã¾ã™...")
        
        # è‡ªå‹•ä¼šè©±é€²è¡Œ - åˆ¶é™ãƒã‚§ãƒƒã‚¯å¾Œã«æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œ
        if (st.session_state.conversation_active and 
            not st.session_state.cost_monitor.is_limit_exceeded()):
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ™ãƒ¼ã‚¹ã§è‡ªå‹•é€²è¡Œï¼ˆ2ç§’é–“éš”ï¼‰
            current_time = time.time()
            should_step = False
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º
            st.write(f"ğŸ” ãƒ‡ãƒãƒƒã‚°: ç¾åœ¨æ™‚åˆ»={current_time:.1f}, æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ™‚åˆ»={st.session_state.last_message_time}")
            
            if st.session_state.last_message_time is None:
                # åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                should_step = True
                st.write("ğŸ” ãƒ‡ãƒãƒƒã‚°: åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆã—ã¾ã™")
            elif current_time - st.session_state.last_message_time >= 2:
                # å‰å›ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰2ç§’çµŒé
                should_step = True
                st.write(f"ğŸ” ãƒ‡ãƒãƒƒã‚°: 2ç§’çµŒé({current_time - st.session_state.last_message_time:.1f}ç§’)ã€æ¬¡ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆã—ã¾ã™")
            else:
                remaining = 2 - (current_time - st.session_state.last_message_time)
                st.write(f"ğŸ” ãƒ‡ãƒãƒƒã‚°: å¾…æ©Ÿä¸­...ã‚ã¨{remaining:.1f}ç§’ã§æ¬¡ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
                time.sleep(remaining)
                st.rerun()
            
            if should_step:
                st.write("ğŸ” ãƒ‡ãƒãƒƒã‚°: conversation_step()ã‚’å®Ÿè¡Œã—ã¾ã™")
                conversation_step(chat_placeholder)
                st.rerun()  # ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ã—ã¦æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸
        else:
            if not st.session_state.conversation_active:
                st.write("ğŸ” ãƒ‡ãƒãƒƒã‚°: ä¼šè©±ãŒåœæ­¢ä¸­")
            if st.session_state.cost_monitor.is_limit_exceeded():
                st.write("ğŸ” ãƒ‡ãƒãƒƒã‚°: ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã«é”ã—ã¾ã—ãŸ")
        
        # åˆ¶é™ãƒ»è­¦å‘Šãƒã‚§ãƒƒã‚¯
        if st.session_state.cost_monitor.is_limit_exceeded():
            st.error("ğŸ”´ ãƒˆãƒ¼ã‚¯ãƒ³ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ä¼šè©±ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            st.session_state.conversation_active = False
        elif st.session_state.cost_monitor.is_warning_threshold():
            st.warning("âš ï¸ ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ãŒ90%ã‚’è¶…ãˆã¾ã—ãŸï¼")
        
        st.divider()
        
        # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
        if st.session_state.messages:
            # ä¼šè©±çµ±è¨ˆ
            st.subheader("ğŸ“ˆ ä¼šè©±çµ±è¨ˆ")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°", st.session_state.total_messages)
            
            with col2:
                speaker_counts = {}
                for msg in st.session_state.messages:
                    speaker = msg['speaker']
                    speaker_counts[speaker] = speaker_counts.get(speaker, 0) + 1
                most_active = max(speaker_counts.items(), key=lambda x: x[1]) if speaker_counts else ("ãªã—", 0)
                st.metric("æœ€ã‚‚æ´»ç™ºãªAI", f"{most_active[0]} ({most_active[1]}å›)")
            
            with col3:
                start_time = st.session_state.messages[0]['timestamp']
                duration = (datetime.now() - start_time).total_seconds() / 60
                st.metric("ä¼šè©±æ™‚é–“", f"{duration:.1f}åˆ†")
    
    else:
        # åˆæœŸç”»é¢
        st.info("ğŸ‘ˆ å·¦å´ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šã‚’è¡Œã„ã€ã€ŒğŸš€ ä¼šè©±é–‹å§‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„")
        
        # ä½¿ã„æ–¹èª¬æ˜
        st.subheader("ğŸ“– ä½¿ã„æ–¹")
        st.markdown("""
        1. **APIã‚­ãƒ¼è¨­å®š**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å„AIã®APIã‚­ãƒ¼ã‚’è¨­å®š
        2. **ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™**: ä½¿ç”¨é‡ã®ä¸Šé™ã‚’è¨­å®šï¼ˆè²»ç”¨åˆ¶å¾¡ï¼‰
        3. **ãƒ†ãƒ¼ãƒé¸æŠ**: AIãŸã¡ãŒè©±ã—åˆã†ãƒˆãƒ”ãƒƒã‚¯ã‚’é¸æŠ
        4. **ä¼šè©±é–‹å§‹**: è¨­å®šå®Œäº†å¾Œã€ã€ŒğŸš€ ä¼šè©±é–‹å§‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯
        5. **è¦³å¯Ÿ**: AIåŒå£«ã®è‡ªå‹•ä¼šè©±ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¦³å¯Ÿ
        """)
        
        # æ³¨æ„äº‹é …
        st.warning("""
        âš ï¸ **æ³¨æ„äº‹é …**
        - APIä½¿ç”¨æ–™é‡‘ãŒç™ºç”Ÿã—ã¾ã™
        - æœ€ä½2ã¤ã®APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™
        - ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’è¨­å®šã—ã¦è²»ç”¨ã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã—ã¦ãã ã•ã„
        """)

if __name__ == "__main__":
    main()
